{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Egress and Persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've engineered your features, manipulated your data and applied classifiications to your data, what if we want to save it somewhere?\n",
    "\n",
    "For the most part, this is the same as the Acquisition step in reverse..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/CompleteUG_clean.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"../data/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To CSV\n",
    "\n",
    "df.to_csv(\"../data/output/Example.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Parquet\n",
    "\n",
    "df.to_parquet(\"../data/output/Example.parquet\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output to SQL Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas DataFrames feature a method to write directly to databases, however Pandas does not have its own connection manager.\n",
    "\n",
    "We need to use SQLAlchemy as an ORM to upload to a SQL Table, and provide a driver for the task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sqlalchemy pyodbc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sqlalchemy\n",
    "#import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "import urllib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a SQL Alchemy Engine\n",
    "params = urllib.parse.quote_plus(\"DRIVER={SQL Server Native Client 11.0};SERVER=.\\\\SQL2017;DATABASE=Sandbox;Trusted_Connection=yes\")\n",
    "\n",
    "engine = create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist data to database\n",
    "\n",
    "df.to_sql(name=\"CompleteUG\", con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and if exists, append more data...\n",
    "\n",
    "df.to_sql(name=\"CompleteUG\", con=engine, if_exists=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or simply replace...\n",
    "\n",
    "df.to_sql(name=\"CompleteUG\", con=engine, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...and more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and more...\n",
    "formats = [\n",
    "{\"text\", \"CSV\", \"read_csv\", \"to_csv\"},\n",
    "{\"text\", \"JSON\", \"read_json\", \"to_json\"},\n",
    "{\"text\", \"HTML\", \"read_html\", \"to_html\"},\n",
    "{\"text\", \"Local clipboard\", \"read_clipboard\", \"to_clipboard\"},\n",
    "{\"binary\", \"MS Excel\", \"read_excel\", \"to_excel\"},\n",
    "{\"binary\", \"HDF5 Format\", \"read_hdf\", \"to_hdf\"},\n",
    "{\"binary\", \"Feather Format\", \"read_feather\", \"to_feather\"},\n",
    "{\"binary\", \"Parquet Format\", \"read_parquet\", \"to_parquet\"},\n",
    "{\"binary\", \"Msgpack\", \"read_msgpack\", \"to_msgpack\"},\n",
    "{\"binary\", \"Stata\", \"read_stata\", \"to_stata\"},\n",
    "{\"binary\", \"SAS\", \"read_sas\", \"\"},\n",
    "{\"binary\", \"Python Pickle Format\", \"read_pickle\", \"to_pickle\"},\n",
    "{\"SQL\", \"SQL\", \"read_sql\", \"to_sql\"},\n",
    "{\"SQL\", \"Google Big Query\", \"read_gbq\", \"to_gbq\"}    \n",
    "]\n",
    "cols = [\"Format Type\", \"Data Description\", \"Reader\", \"Writer\"]\n",
    "pd.DataFrame(formats, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: http://pandas.pydata.org/pandas-docs/stable/user_guide/io.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
